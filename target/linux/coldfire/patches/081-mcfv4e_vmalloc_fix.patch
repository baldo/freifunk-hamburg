From db94c8c3ec831b5fab828487ba05041bc048fccf Mon Sep 17 00:00:00 2001
From: Kurt Mahan <kmahan@freescale.com>
Date: Tue, 15 Jul 2008 17:48:11 -0600
Subject: [PATCH] Move VMALLOC region to a valid area.

LTIBName: mcfv4e-vmalloc-fix
Signed-off-by: Kurt Mahan <kmahan@freescale.com>
---
 arch/m68k/mm/cf-mmu.c      |    7 +------
 include/asm-m68k/pgtable.h |    6 +++++-
 2 files changed, 6 insertions(+), 7 deletions(-)

--- a/arch/m68k/mm/cf-mmu.c
+++ b/arch/m68k/mm/cf-mmu.c
@@ -35,7 +35,7 @@
 #include <asm/coldfire.h>
 #include <asm/tlbflush.h>
 
-#define KMAPAREA(x)	((x >= KMAP_START) && ( x < KMAP_END))
+#define KMAPAREA(x)	((x >= VMALLOC_START) && ( x < KMAP_END))
 
 #undef DEBUG
 
@@ -62,11 +62,6 @@ void free_initmem(void)
 	unsigned long start = (unsigned long)&__init_begin;
 	unsigned long end = (unsigned long)&__init_end;
 
-/* 
- * JKM -- revisit -- the latest round of vmlinux.lds changes has caused
- * a little grief with how init areas are handled.  With the new toolchain
- * release I'll fix this.
- */
 	printk(KERN_INFO "free_initmem: __init_begin = 0x%lx  __init_end = 0x%lx\n", start, end);
 
 	addr = (unsigned long)&__init_begin;
--- a/include/asm-m68k/pgtable.h
+++ b/include/asm-m68k/pgtable.h
@@ -73,7 +73,9 @@
 #define KMAP_START     0x0DC00000
 #define KMAP_END       0x0E000000
 #elif defined(CONFIG_COLDFIRE)
-#define KMAP_START	0xd0000000
+#define	VMALLOC_START	0xc0000000
+#define VMALLOC_END	0xcfffffff
+#define KMAP_START	(VMALLOC_END + 1)
 #define KMAP_END	0xe0000000
 #else
 #define	KMAP_START	0xd0000000
@@ -88,9 +90,11 @@
  * The vmalloc() routines leaves a hole of 4kB between each vmalloced
  * area for the same reason. ;)
  */
+#if !defined(CONFIG_COLDFIRE)
 #define VMALLOC_OFFSET	(8*1024*1024)
 #define VMALLOC_START (((unsigned long) high_memory + VMALLOC_OFFSET) & ~(VMALLOC_OFFSET-1))
 #define VMALLOC_END KMAP_START
+#endif
 #else
 extern unsigned long vmalloc_end;
 #define VMALLOC_START 0x0f800000
